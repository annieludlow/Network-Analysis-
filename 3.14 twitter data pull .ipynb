{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, sys, time\n",
    "from zipfile import ZipFile\n",
    "from birdy.twitter import AppClient, UserClient, TwitterRateLimitError\n",
    "from ratelimiter import RateLimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSUMER_KEY = 'F0pfYPKH22Egu5Fajzjvw1vO0'\n",
    "CONSUMER_SECRET = 'Rt67vDPt5JeROHe2lEuFxvK6saul6DsMAtocYrAU2gn1ieLxZB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = 'tweets'\n",
    "MAX_TWEETS = 10000 # max results for a search\n",
    "max_id = None\n",
    "_client = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client(consumer_key=None, consumer_secret=None):\n",
    "    global _client\n",
    "    if consumer_key is None:\n",
    "        consumer_key = CONSUMER_KEY\n",
    "    if consumer_secret is None:\n",
    "        consumer_secret = CONSUMER_SECRET\n",
    "    if _client is None:\n",
    "        _client = AppClient(consumer_key, consumer_secret)\n",
    "        access_token = _client.get_access_token()\n",
    "        _client = AppClient(consumer_key, consumer_secret, access_token)\n",
    "    return _client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limited(until):\n",
    "    duration = int(round(until - time.time()))\n",
    "    print('Rate limited, sleeping for {:d} seconds'.format(duration))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "@RateLimiter(max_calls=440, period=60*15, callback=limited)\n",
    "def fetch_tweets(query, consumer_key=None, consumer_secret=None):\n",
    "    global max_id\n",
    "    print(f'Fetching: \"{query}\" TO MAX ID: {max_id}')\n",
    "    try:\n",
    "        tweets = client(consumer_key, consumer_secret).api.search.tweets.get(\n",
    "            q=query,\n",
    "            count=100,\n",
    "            max_id=max_id).data['statuses']\n",
    "    except TwitterRateLimitError:\n",
    "        sys.exit(\"You've reached your Twitter API rate limit. \"\\\n",
    "            \"Wait 15 minutes before trying again\")\n",
    "    try:\n",
    "        id_ = min([tweet['id'] for tweet in tweets])\n",
    "    except ValueError:\n",
    "        return None\n",
    "    if max_id is None or id_ <= max_id:\n",
    "        max_id = id_ - 1\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_max_id(file_list):\n",
    "    global max_id\n",
    "    for fn in file_list:\n",
    "        n = int(fn.split('.')[0])\n",
    "        if max_id is None or n < max_id:\n",
    "            max_id = n - 1\n",
    "    if max_id is not None:\n",
    "        print('Found previously fetched tweets. Setting max_id to %d' % max_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def halt(_id):\n",
    "    print('Reached historically fetched ID: %d' % _id)\n",
    "    print('In order to re-fetch older tweets, ' \\\n",
    "        'remove tweets from the output directory or output zip file.')\n",
    "    sys.exit('\\n!!IMPORTANT: Tweets older than 7 days will not be re-fetched')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_twitter(query, consumer_key=None, consumer_secret=None,\n",
    "            newtweets=False, dozip=True, verbose=False):\n",
    "    output_dir = os.path.join(OUTPUT_DIR, '_'.join(query.split()))\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    if dozip:\n",
    "        fn = os.path.join(output_dir, '%s.zip' % '_'.join(query.split()))\n",
    "        outzip = ZipFile(fn, 'a')\n",
    "    if not newtweets:\n",
    "        if dozip:\n",
    "            file_list = [f for f in outzip.namelist() if f.endswith('.json')]\n",
    "        else:\n",
    "            file_list = [f for f in os.listdir(output_dir) if f.endswith('.json')]\n",
    "        initialize_max_id(file_list)\n",
    "    while True:\n",
    "        try:\n",
    "            tweets = fetch_tweets(\n",
    "                query,\n",
    "                consumer_key=consumer_key,\n",
    "                consumer_secret=consumer_secret)\n",
    "            if tweets is None:\n",
    "                print('Search Completed')\n",
    "                if dozip:\n",
    "                    outzip.close()\n",
    "                break\n",
    "            for tweet in tweets:\n",
    "                if verbose:\n",
    "                    print(tweet['id'])\n",
    "                fn = '%d.json' % tweet['id']\n",
    "                if dozip:\n",
    "                    if fn in (file_list):\n",
    "                        outzip.close()\n",
    "                        halt(tweet['id'])\n",
    "                    else:\n",
    "                        outzip.writestr(fn, json.dumps(tweet, indent=4))\n",
    "                        file_list.append(fn)\n",
    "                else:\n",
    "                    path = os.path.join(output_dir, fn)\n",
    "                    if fn in (file_list):\n",
    "                        halt(tweet['id'])\n",
    "                    else:\n",
    "                        with open(path, 'w') as outfile:\n",
    "                            json.dump(tweet, outfile, indent=4)\n",
    "                        file_list.append(fn)\n",
    "                if len(file_list) >= MAX_TWEETS:\n",
    "                    if fn in (file_list):\n",
    "                        outzip.close()\n",
    "                    sys.exit('Reached maximum tweet limit of: %d' % MAX_TWEETS)\n",
    "        except:\n",
    "            if dozip:\n",
    "                outzip.close()\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching: \"UberEats\" TO MAX ID: None\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112897677916696576\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112891541834481664\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112886002090049535\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112878799220236287\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112872895292862463\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112864824193474559\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112858424604278786\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112851887508934655\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112846438717784064\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112839410297569285\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112832158664601599\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112823728797310975\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112816676762869759\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112808603336011775\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112800056996880383\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112792216659853311\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112784666216394754\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112775472193200128\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112768907356467199\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112761794655862784\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112754445564235780\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112747945198129151\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112741558279786495\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112736492978233345\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112729992612454399\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112723358062440448\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112716138230759423\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112709321454817279\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112701754171445247\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112694638857482239\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112686429983772672\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112679044984635392\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112670786349719551\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112662605766615039\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112654274935152642\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112646140179025919\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112637724966608896\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112629534770135040\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112619272038014975\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112611961718468608\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112601940171591679\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112593685441449983\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112586635819008000\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112580142008881151\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112572965172862975\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112565686381887487\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112559435119882240\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112553871635812351\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112547948921909247\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112543365336170498\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112537181426454527\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112530771816923135\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112526836959977477\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112520533348741119\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112513245900951552\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112508217387433986\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112502746853175296\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112497299022888959\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112491328183697407\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112486590180397065\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112479992649269247\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112473398469234687\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112467437654441983\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112460017733558271\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112453402938662911\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112447818570948607\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112441814433193985\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112436148939444225\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112429983635374079\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112424366594289665\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112417798821691396\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112412971609669631\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112408483234607103\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112403935841660929\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112398325884411904\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112393366447243263\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112388952785215487\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112384300111089665\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112379172767199232\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112374627219714047\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112370705327448063\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112366362272231423\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112361607730995199\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112355904786063359\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112351218293071872\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112346543149871106\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112341843679895554\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112336083709116416\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112330583919726594\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112326242169249791\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112320784645545983\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112315631876005888\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112310048741482495\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112305877606952959\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112300012510175231\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112293679023063039\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112288198128857087\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112282665254711295\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112276116792897535\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112272399381069823\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112267890693160959\n",
      "Fetching: \"UberEats\" TO MAX ID: 1112263174651301893\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "Reached maximum tweet limit of: 10000",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Reached maximum tweet limit of: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#search_twitter(\"Grubhub\")\n",
    "search_twitter(\"UberEats\")\n",
    "#search_twitter(\"DoorDash\")          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
